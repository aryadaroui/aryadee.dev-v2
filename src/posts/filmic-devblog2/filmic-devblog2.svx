---
title: "Filmic devblog 2: film grain and halation ðŸ‘¼"
date: 31 Mar 2021
update:
thumbnail: ./thumbnail.png
tags: 
  - Python
  - image processing
  - Jupyter
  - code
---

<script>
import grain_params from './grain_params.png'
import grain_applied from './grain_applied.png'
import grain from './grain.png'
import halation_steps from './halation_steps.webp'
import halation_applied from './halation_applied.png'
import tone_response_curve from './tone_response_curve.json'
import threshold_curve from './threshold_curve.json'

</script>

# Background and setup

In this devblog, we cover testing the concepts behind Filmic's features in Python. We'll be applying functions to alter images in a pleasing way, and confirming these ideas work before we try building UI and GPU shader code around them.

This is a direct continuation of the last blog, where we used interpolated functions to generate a tone curve and color response for the image. Now, we'll be adding film grain and halation. This post is also available as an [interactive Python (Jupyter) notebook](https://github.com/aryadaroui/filmic-devblog).

The setup is available in the callout below, but let's jump right into the meat of things with tone-responsive film grain.

<Callout title="Setup" icon="code">

```python
# standard numpy and typing
import numpy as np
# image read, write, and conversion tools
import cv2
from PIL import Image

# to generate our cubic interpolation functions
from scipy.interpolate import interp1d

# nice image and plot display in our notebook
import matplotlib.pyplot as plt # for our image output

import plotly.graph_objects as go # for our plots, because plotly is awesome

# to generate simplex noise for fake film grain
# gives unresolved import error in  VS Code Jupyter notebook, but it still works
from opensimplex import noise2array 

# to apply gaussian blur for halation
from scipy.ndimage import gaussian_filter

# makes the size of our images a bit bigger in our notebook.
plt.rcParams['figure.figsize'] = [12, 8]
plt.rcParams['figure.dpi'] = 100
```

We also have some reusable visualization functions, but the code block is quite long, so you can check them out in the [notebook](https://github.com/aryadaroui/filmic-devblog). The logic behind them isn't important.

</Callout>

# Film grain

Two well known algorithms come to mind for synthesis of granular noise (both invented by the same person!), *Perlin* and *Simplex* noise. [This is a nice blog post](https://www.bit-101.com/blog/2021/07/perlin-vs-simplex/) that goes into their differences a bit. Most importantly for us, I found that Simplex noise,

1.  matches the look of film grain better
2.  just had its patent expire

Let's consider how we can adjust some parameters in our noise generation,

*   `grain_size`: to zoom in and out of the noise pattern; lets us emulate granule size
*   `intensity`: amplifies the noise and makes the transitions less smooth and more contrasty
*   `offset`: adjusts the mean (center value) of the noise

Our usage can be abstracted to

$$
\mathrm{simplex}(\mathrm{size}) \times \mathrm{intensity} + \mathrm{offset}
$$

Mind that when the image is rasterized, the values will be clamped between 0.0 and 1.0. We should look at examples with different argument values first to see what would best suit our needs.

```python
def grain_array(size, intensity, offset):
    '''generates a 50x50 array of simplex noise'''
    return noise2array(np.linspace(0, 100 / size, num=50), np.linspace(0, 100 / size, num=50)) * intensity + offset 

# # # visualization code # # #
# output at different argument values. The middle values remains constant between tests
fig, axarr = plt.subplots(3,3)

axarr[0, 0].imshow(np.clip(grain_array(  5,  1.0,  0.5 ), 0.0, 1.0), cmap='gray')
axarr[0, 1].imshow(np.clip(grain_array( 10,  1.0,  0.5 ), 0.0, 1.0), cmap='gray')
axarr[0, 2].imshow(np.clip(grain_array( 20,  1.0,  0.5 ), 0.0, 1.0), cmap='gray')

axarr[1, 0].imshow(np.clip(grain_array( 10,  0.1,  0.5 ), 0.0, 1.0), cmap='gray')
axarr[1, 1].imshow(np.clip(grain_array( 10,  1.0,  0.5 ), 0.0, 1.0), cmap='gray')
axarr[1, 2].imshow(np.clip(grain_array( 10, 10.0,  0.5 ), 0.0, 1.0), cmap='gray')

axarr[2, 0].imshow(np.clip(grain_array( 10,  1.0,  0.0  ), 0.0, 1.0), cmap='gray')
axarr[2, 1].imshow(np.clip(grain_array( 10,  1.0,  0.5  ), 0.0, 1.0), cmap='gray')
axarr[2, 2].imshow(np.clip(grain_array( 10,  1.0,  1.0  ), 0.0, 1.0), cmap='gray')

# make it pretty
fig.set_facecolor('#0f0f0f')
fig.subplots_adjust(wspace = -0.6)

axarr[0, 0].axis('off'); axarr[0, 0].set_title('grain size = 5', color='#CCCCCC') 
axarr[0, 1].axis('off'); axarr[0, 1].set_title('grain size = 10', color='#CCCCCC')
axarr[0, 2].axis('off'); axarr[0, 2].set_title('grain size = 20', color='#CCCCCC')

axarr[1, 0].axis('off'); axarr[1, 0].set_title('intensity = 0.1', color='#CCCCCC')
axarr[1, 1].axis('off'); axarr[1, 1].set_title('intensity = 1.0', color='#CCCCCC') 
axarr[1, 2].axis('off'); axarr[1, 2].set_title('intensity = 10.0', color='#CCCCCC')

axarr[2, 0].axis('off'); axarr[2, 0].set_title('offset = 0.0', color='#CCCCCC')
axarr[2, 1].axis('off'); axarr[2, 1].set_title('offset = 0.5', color='#CCCCCC')
axarr[2, 2].axis('off'); axarr[2, 2].set_title('offset = 1.0', color='#CCCCCC')
```

<ImgCap src={grain_params} caption="Grain texture at varying size, intensity, and offset" make_fit=false/>


Now we have a better sense of what the granular noise looks like. Let's choose some values for our parameters and make an array big enough for our test image. This may take a few seconds to run on our CPU.


```python
img_rgb1 = read_img('test_pic1.jpg')
img_hls = rgb_to_hls(img_rgb1)

# we choose what we hope are reasonable values
grain_size = 1.5
intensity = 0.4
offset = 0.0

noise = noise2array(
    np.linspace(0, img_hls.shape[1]/grain_size , num=img_hls.shape[1]),
    np.linspace(0, img_hls.shape[0]/grain_size, num=img_hls.shape[0])
) * intensity + offset

# quickly check the stats of our noise
print('noise max:', round(noise.max(), 2))
print('noise min:', round(noise.min(), 2))
print('noise mean:', round(noise.mean(), 2))

# don't forget that we have values going below 0.0 that are getting clipped on output!
show_img_gray(noise)

```

<Callout title="Terminal output" icon="terminal">

```
noise max: 0.35
noise min: -0.35
noise mean: -0.0
```

</Callout>

<ImgCap src={grain} caption="Our film grain texture" make_fit=false/>

Now, we do what we did earlier and create another color response curve, but this time it applies the granular noise with respect to the image's tonality. Typically, we see more noise in darker regions, so lets set our response curve to match that.


```python
img_hls = rgb_to_hls(img_rgb1) # reset our img_hls

tone_response_data_x = [0.0, 0.25, 0.5, 0.75, 1.0]
tone_response_data_y = [0.25, 0.5, 0.2, 0.1,  0.1] # greater response in the shadows
# color response with respect to luminosity, i.e. tone
f_tone_response_curve = interp1d(tone_response_data_x, tone_response_data_y, kind='cubic')
plot_tone_curve(tone_response_data_y, f_tone_response_curve, label='tone response')

img_hls[:, :, 1] = img_hls[:, :, 1] + f_tone_response_curve(img_hls[:, :, 1]) * noise
img_out = hls_to_rgb(img_hls)

show_img_rgb(img_out)

# # the grain is hard to see in a low resolution notebook preview. You may want to save the file with the line below.
# write_img(img_out, 'test_pic1_grain.jpg')
```

<ExpandingBox>
  <Plot plot_json={tone_response_curve} />
</ExpandingBox>


<ImgCap src={grain_applied} caption="The film grain applied to our image" make_fit=false/>

Looking good! The next feature on our list is halation.

# Halation

Put simply, halation is red fringing caused by backscattering in the film emulsion. We're going to emulate it by thresholding the red channels' brightest pixels, diffusing it with a gaussian blur, and then adding it on top of the original image.

$$
R_\alpha = \mathrm{threshold\_curve}(R) \\
R' = R + \mathrm{gaussian}(\mathrm{radius}, \, R_\alpha) \times \mathrm{opacity}
$$

We also give the option to for strength of the effect by multiplying by $\mathrm{opacity}$.

```python
# we should use a new image that has stronger highlights and contrast to better display the effect
img_rgb2 = read_img('test_pic2.jpg') 

# set our parameters
radius = 20
opacity = 0.8

# pass only the *highest* intensity pixels
threshold_data_x = [0.0, 0.99, 1.0] 
threshold_data_y = [0.0, 0.0, 1.0]
f_threshold_curve = interp1d(threshold_data_x, threshold_data_y, kind='linear') # we don't need a fancy cubic to threshold; let's just go linear

# threshold on red channel
r_alpha = f_threshold_curve(img_rgb2[:, :, 0]) 

# this process is a bit more complicated so we'll look at intermediate steps
r_alpha_mask = np.zeros(img_rgb2.shape, dtype=np.float32) # make a copy of the image with the right shape
r_alpha_mask[:, :, 0] = r_alpha

gaussian_mask = np.zeros(img_rgb2.shape, dtype=np.float32)
gaussian_mask[:, :, 0] = gaussian_filter(r_alpha_mask[:, :, 0], radius) # blur it

rescaled  = np.zeros(img_rgb2.shape, dtype=np.float32)
rescaled[:, :, 0] = gaussian_mask[:, :, 0] * opacity # apply opacity scaling

# # # visualization code # # #
# what our threshold curve looks like
plot_thresh_curve(threshold_data_x, threshold_data_y, f_threshold_curve)
fig, axarr = plt.subplots(2, 2)
fig.set_facecolor('#0f0f0f')
fig.subplots_adjust(wspace = -0.7)
axarr[0, 0].imshow(img_rgb2); axarr[0, 0].axis('off'); axarr[0, 0].set_title('original', color='#CCCCCC') 
axarr[0, 1].imshow(r_alpha_mask); axarr[0, 1].axis('off'); axarr[0, 1].set_title('threshold', color='#CCCCCC') 
axarr[1, 0].imshow(gaussian_mask); axarr[1, 0].axis('off'); axarr[1, 0].set_title('gaussian blur', color='#CCCCCC') 
axarr[1, 1].imshow(rescaled); axarr[1, 1].axis('off'); axarr[1, 1].set_title('rescale opacity', color='#CCCCCC') 
```

<ExpandingBox>
  <Plot plot_json={threshold_curve} />
</ExpandingBox>

<ImgCap src={halation_steps} caption="The intermediate steps in applying halation" make_fit=false/>


Okay now let's actually add the `rescale_opacity` on top of the original image and see the outcome.
```python
img_out = img_rgb2.copy() # make a copy so we can see before and after
img_out[:, :, 0] = img_rgb2[:, :, 0] + opacity * (gaussian_filter(img_rgb2[:, :, 0] * r_alpha, radius))

show_img_left_right(img_rgb2, img_out)
```

<ImgCap src={halation_applied} caption="Halation applied to our image" make_fit=false/>

# Conclusion

Between these first two devblogs, we've accomplished all the major features we wanted to hit--and it looks quite good! Still, two things stick out during this process:

1.  There are so many parameters to adjust! If we want to select the best values for our artistic expression, we need a proper GUI with sliders and all.
2.  This Python code, while easy to read, is kind of slow! It would be ideal to use a faster language and/or hardware acceleration. That way, we could see the updates from the GUI in real time.

Well, we will explore both of these issues in the coming devblogs. We'll dive into how to use D3.js and svelte to make a a reactive GUI component, and how to use WebGL 2.0 and shaders to utilize our GPU.

# Appendix

As with any good technical writeup, we need to quickly cover the rough edges we glossed over.

## Luminosity vs. tonality

I've been fast and loose with my usage of the terms luminosity and tonality. Luminosity has a very specific meaning in how it affects the HSL color space, but tonality is more of an umbrella term in that it's just a different shade of the same color, i.e. lighter or darker. When I use the term tone, I'm usually referring to the RGB intensity together in unison, rather than the L in HSL.

You could argue that luminosity and value are both ways of describing tonality. And that's important, because Filmic currently (as of v0.3) uses HSV and our examples in this article are all HSL.

## Halation is complicated

Halation has a lot of nuances we haven't capture in our example:

*   distribution of halation isn't necesarrily gaussian
*   it isn't always dispersed pure red, i.e. need hue adjustment
*   because we're working with clipped data, our application is imperfect and can cause excess saturation with additive methods
*   halation isn't so different from bloom; can we exploit this for efficiency if we want bloom as a feature too?

There's a lot more in this I need to explore, and will do so in its own article. Until I've figured it out, I'm leaving it out of filmic.
